# Server Configuration
NODE_ENV=development
PORT=3002
HOST=localhost

# LLM Provider - OpenAI
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.3
OPENAI_MAX_TOKENS=2000
OPENAI_TIMEOUT=30000

# Alternative LLM Providers (Optional)
# ANTHROPIC_API_KEY=
# AWS_BEDROCK_REGION=us-east-1

# AI Med Agents Configuration
USE_RULE_BASED_FALLBACK=true
PREFER_RULE_BASED_FOR_SPEED=false
CACHE_ENABLED=true
CACHE_TTL=3600

# Backend Integration
BACKEND_URL=http://localhost:3001
BACKEND_API_KEY=your-backend-api-key

# Logging
LOG_LEVEL=info
LOG_FORMAT=json
LOG_FILE=./logs/orchestrator.log

# Performance
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30000
RETRY_ATTEMPTS=3
RETRY_DELAY=1000

# Feature Flags
ENABLE_SOAP_GENERATION=true
ENABLE_ALERTS_DETECTION=true
ENABLE_FOLLOWUP_SUGGESTIONS=true
ENABLE_METRICS=true
ENABLE_TRACING=false

# Security
CORS_ORIGIN=http://localhost:3000,http://localhost:3001
RATE_LIMIT_WINDOW=60000
RATE_LIMIT_MAX_REQUESTS=100

# Monitoring
HEALTH_CHECK_INTERVAL=30000
METRICS_PORT=9090
